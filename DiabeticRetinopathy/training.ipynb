{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdr.EfficientNet import *\n",
    "from hdr.preprocess import *\n",
    "\n",
    "# Data Prepration.\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "\n",
    "# version: width, depth, res, dropout rate\n",
    "efficient_net_config = {\n",
    "\"b0\" : (1.0, 1.0, 224, 0.2),\n",
    "\"b1\" : (1.0, 1.1, 240, 0.2),\n",
    "\"b2\" : (1.1, 1.2, 260, 0.3),\n",
    "\"b3\" : (1.2, 1.4, 300, 0.3),\n",
    "\"b4\" : (1.4, 1.8, 380, 0.4),\n",
    "\"b5\" : (1.6, 2.2, 456, 0.4),\n",
    "\"b6\" : (1.8, 2.6, 528, 0.5),\n",
    "\"b7\" : (2.0, 3.1, 600, 0.5)\n",
    "}\n",
    "\n",
    "version = 'b0'\n",
    "width_mult, depth_mult, res, dropout_rate = efficient_net_config[version]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getcwd() + \"//resources\"  \n",
    "net = EfficientNet(width_mult, depth_mult, dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training labels stored in [trainLabels.csv]. \n",
      " >>If this file is incorrect, ensure only 1 file labelled [trainLabels.csv]]!!\n",
      "\n",
      "Training set consists of 10 images.\n"
     ]
    }
   ],
   "source": [
    "# Reading the labels.\n",
    "print(f\"\\nTraining labels stored in [{os.listdir(DATA_DIR + \"//train\")[1]}]. \\n >>If this file is incorrect, ensure only 1 file labelled [trainLabels.csv]]!!\")\n",
    "\n",
    "try:\n",
    "    trainlabel = pd.read_csv(DATA_DIR + \"//train//\" + os.listdir(DATA_DIR + \"//train\")[1])\n",
    "except Exception as e:\n",
    "    print(\"\\nTraining Labels cannot be loaded\", e)\n",
    "\n",
    "# load in files\n",
    "trainimages = os.listdir(DATA_DIR + \"//data//sample\")\n",
    "# remove the \".jpeg\"\n",
    "trainimages_nojpeg = [x.split(\".\")[0] for x in trainimages]\n",
    "# get all current training images\n",
    "trainlabel_F =  trainlabel[trainlabel['image'].isin(trainimages_nojpeg)]\n",
    "\n",
    "print(f\"\\nTraining set consists of {len(trainlabel_F)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Dataloaders.\n",
    "# Hyper-params\n",
    "BATCH_SIZE = 32\n",
    "NUM_OF_CLASSES = 5\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# Datasets\n",
    "train_dataset = DiabeticRetinopathyDataset(DATA_DIR + \"//data//sample\", data_transforms['train'])\n",
    "val_dataset = DiabeticRetinopathyDataset(DATA_DIR + \"//data//sample\", data_transforms['val'])\n",
    "\n",
    "\n",
    "# Datloaders\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance on test data\n",
    "def calculate_loss_and_accuracy(model, dataloader, size_of_dataset, criterion, device):\n",
    "    \n",
    "    # Now set model to validation mode.\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    \n",
    "     # Processing the Test Loader\n",
    "    for (inputs, labels) in dataloader:\n",
    "        \n",
    "        # Load data to device.\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Outputs\n",
    "        outputs = model(inputs)\n",
    "        _ , preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Outputs\n",
    "        outputs = model(inputs)\n",
    "        _ , preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Loss and Backpropagation.\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_accuracy += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss/size_of_dataset\n",
    "    epoch_accuracy = running_accuracy/size_of_dataset\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def train(model, criterion, optimizer, scheduler, num_of_epochs, device, train_loader):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    #track_training_loss = []\n",
    "    #track_val_loss = []\n",
    "\n",
    "    for epoch in range(num_of_epochs):\n",
    "\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_of_epochs}')\n",
    "        print('-'*30)\n",
    "\n",
    "        model.train() # Setting model to train.\n",
    "        running_loss = 0\n",
    "        running_accuracy = 0\n",
    "\n",
    "        # Processing the Train Loader\n",
    "        for (inputs, labels) in train_loader:\n",
    "\n",
    "            # Load data to device.\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # zero the parameter gradients\n",
    "\n",
    "            # Outputs\n",
    "            outputs = model(inputs)\n",
    "            _ , preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Loss and Backpropagation.\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item()*inputs.size(0)\n",
    "            running_accuracy += torch.sum(preds == labels.data)\n",
    "        \n",
    "        scheduler.step()\n",
    "        epoch_loss = running_loss/len(train_dataset)\n",
    "        epoch_accuracy = running_accuracy/len(train_dataset)\n",
    "        #track_training_loss.append(epoch_loss) # Loss Tracking\n",
    "\n",
    "        print(f'Training Loss: {epoch_loss:.4f} Training Acc.: {epoch_accuracy:.4f}')\n",
    "\n",
    "        # Now set model to validation mode.\n",
    "        model.eval()\n",
    "\n",
    "        val_loss, val_accuracy = calculate_loss_and_accuracy(model, val_loader, len(val_dataset), criterion)\n",
    "\n",
    "        if val_accuracy > best_acc:\n",
    "            print(\"Found better model...\")\n",
    "            print('Updating the model weights....\\n')\n",
    "            print(f'Val Loss: {val_loss:.4f} Val Acc.: {val_accuracy:.4f}\\n')\n",
    "\n",
    "            best_acc = val_accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "     \n",
    "    model.load_state_dict(best_model_wts) # update model\n",
    "    \n",
    "    return  model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
